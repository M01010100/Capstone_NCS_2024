{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('payment_fraud.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['paymentMethod_encoded'] = label_encoder.fit_transform(df['paymentMethod'])\n",
    "\n",
    "features = ['accountAgeDays', 'numItems', 'localTime', 'paymentMethod_encoded', 'paymentMethodAgeDays']\n",
    "X = df[features].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)  # Fit on training data and transform it\n",
    "#X_test = scaler.transform(X_test)  # Transform test data using the same scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encryption setup with TenSEAL\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21,40])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=16384, coeff_mod_bit_sizes=[60, 40, 40, 60, 60])\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2 ** 40\n",
    "\n",
    "# Encrypt training and testing data\n",
    "X_train_encrypted = [ts.ckks_vector(context, x) for x in X_train]\n",
    "X_test_encrypted = [ts.ckks_vector(context, x) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31376, 1)\n",
      "(31376, 1)\n",
      "[[<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC1716C0>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC173160>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BA9960A30>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BA98621A0>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC1731C0>]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'CKKSVector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_encrypted_np\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_encrypted_np[:\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m X_train_encrypted_np \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_encrypted_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(X_train_encrypted_np)) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(X_train_encrypted_np)):\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'CKKSVector'"
     ]
    }
   ],
   "source": [
    "X_train_encrypted_np = np.array( X_train_encrypted)\n",
    "#X_test_encrypted_np = np.array( X_test_encrypted)\n",
    "X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], -1)\n",
    "#X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], X_test_encrypted_np.shape[1])\n",
    "print(X_train_encrypted_np.shape)\n",
    "#print(X_test_encrypted_np.shape)\n",
    "print(X_train_encrypted_np.shape)\n",
    "print(X_train_encrypted_np[:5])\n",
    "X_train_encrypted_np = X_train_encrypted_np.astype(np.float64)\n",
    "y_train = y_train.astype(np.float64)\n",
    "if np.any(np.isnan(X_train_encrypted_np)) or np.any(np.isinf(X_train_encrypted_np)):\n",
    "    print(\"NaN or Inf detected in X_train_encrypted_np\")\n",
    "if np.any(np.isnan(y_train)) or np.any(np.isinf(y_train)):\n",
    "    print(\"NaN or Inf detected in y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encrypted_np_small = X_train_encrypted_np[:100]  # Use only the first 100 samples\n",
    "y_train_small = y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train_encrypted_np.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Profile the training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{epochs}\")\n",
    "    predictions = batch_predict(X_train_encrypted_np, weights)\n",
    "    gradients = compute_gradients(X_train_encrypted_np, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):\n",
    "        print(\"NaN or Inf detected in predictions\")\n",
    "        break\n",
    "    if np.any(np.isnan(gradients)) or np.any(np.isinf(gradients)):\n",
    "        print(\"NaN or Inf detected in gradients\")\n",
    "        break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Training loop with optimizations\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: calculate predictions\n",
    "    predictions = batch_predict(X_train, weights)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    gradients = compute_gradients(X_train, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
