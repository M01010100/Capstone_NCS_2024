{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('payment_fraud.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['paymentMethod_encoded'] = label_encoder.fit_transform(df['paymentMethod'])\n",
    "\n",
    "features = ['accountAgeDays', 'numItems', 'localTime', 'paymentMethod_encoded', 'paymentMethodAgeDays']\n",
    "X = df[features].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data and transform it\n",
    "X_test = scaler.transform(X_test)  # Transform test data using the same scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encryption setup with TenSEAL\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=16384, coeff_mod_bit_sizes=[60, 40, 40, 60, 60])\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2 ** 40\n",
    "\n",
    "# Encrypt training and testing data\n",
    "X_train_encrypted = [ts.ckks_vector(context, x) for x in X_train]\n",
    "X_test_encrypted = [ts.ckks_vector(context, x) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31376, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_encrypted_np = np.array( X_train_encrypted)\n",
    "#X_test_encrypted_np = np.array( X_test_encrypted)\n",
    "X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], -1)\n",
    "#X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], X_test_encrypted_np.shape[1])\n",
    "print(X_train_encrypted_np.shape)\n",
    "#print(X_test_encrypted_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Training loop with optimizations\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Forward pass: calculate predictions\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_encrypted_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Calculate gradients and update weights\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m compute_gradients(X_train_encrypted_np, y_train, predictions)\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mbatch_predict\u001b[1;34m(X, weights)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_predict\u001b[39m(X, weights):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Simple linear model prediction (e.g., X @ weights for matrix multiplication)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\CVvid\\lib\\site-packages\\tenseal\\tensors\\abstract_tensor.py:116\u001b[0m, in \u001b[0;36mAbstractTensor.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstractTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\CVvid\\lib\\site-packages\\tenseal\\tensors\\ckksvector.py:103\u001b[0m, in \u001b[0;36mCKKSVector.mul\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    101\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operand(other, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m other\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\CVvid\\lib\\site-packages\\tenseal\\tensors\\abstract_tensor.py:79\u001b[0m, in \u001b[0;36mAbstractTensor._wrap\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstractTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new tensor object wrapping the low level tensor object\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\CVvid\\lib\\site-packages\\tenseal\\tensors\\ckksvector.py:9\u001b[0m, in \u001b[0;36mCKKSVector.__init__\u001b[1;34m(self, context, vector, scale, data)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCKKSVector\u001b[39;00m(AbstractTensor):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     11\u001b[0m         context: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mts.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m         vector\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m         scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m         data: ts\u001b[38;5;241m.\u001b[39m_ts_cpp\u001b[38;5;241m.\u001b[39mCKKSVector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m     ):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Constructor method for the CKKSVector object, which can store a vector of\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m        float numbers in encrypted form, using the CKKS homomorphic encryption scheme.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m            CKKSVector object.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;66;03m# wrapping\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train_encrypted_np.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Training loop with optimizations\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: calculate predictions\n",
    "    predictions = batch_predict(X_train_encrypted_np, weights)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    gradients = compute_gradients(X_train_encrypted_np, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Weights update: [[-1.40553553e+41 -1.40553553e+41 -1.40553553e+41 ... -1.40553553e+41\n",
      "  -1.40553553e+41 -1.40553553e+41]\n",
      " [-9.30648480e+37 -9.30648480e+37 -9.30648480e+37 ... -9.30648480e+37\n",
      "  -9.30648480e+37 -9.30648480e+37]\n",
      " [-4.13955718e+38 -4.13955718e+38 -4.13955718e+38 ... -4.13955718e+38\n",
      "  -4.13955718e+38 -4.13955718e+38]\n",
      " [-2.88914277e+37 -2.88914277e+37 -2.88914277e+37 ... -2.88914277e+37\n",
      "  -2.88914277e+37 -2.88914277e+37]\n",
      " [-1.93431535e+40 -1.93431535e+40 -1.93431535e+40 ... -1.93431535e+40\n",
      "  -1.93431535e+40 -1.93431535e+40]]\n",
      "Epoch 20/100, Weights update: [[-4.33216008e+82 -4.33216008e+82 -4.33216008e+82 ... -4.33216008e+82\n",
      "  -4.33216008e+82 -4.33216008e+82]\n",
      " [-2.86845697e+79 -2.86845697e+79 -2.86845697e+79 ... -2.86845697e+79\n",
      "  -2.86845697e+79 -2.86845697e+79]\n",
      " [-1.27589975e+80 -1.27589975e+80 -1.27589975e+80 ... -1.27589975e+80\n",
      "  -1.27589975e+80 -1.27589975e+80]\n",
      " [-8.90495382e+78 -8.90495382e+78 -8.90495382e+78 ... -8.90495382e+78\n",
      "  -8.90495382e+78 -8.90495382e+78]\n",
      " [-5.96197218e+81 -5.96197218e+81 -5.96197218e+81 ... -5.96197218e+81\n",
      "  -5.96197218e+81 -5.96197218e+81]]\n",
      "Epoch 30/100, Weights update: [[-1.33526407e+124 -1.33526407e+124 -1.33526407e+124 ... -1.33526407e+124\n",
      "  -1.33526407e+124 -1.33526407e+124]\n",
      " [-8.84119578e+120 -8.84119578e+120 -8.84119578e+120 ... -8.84119578e+120\n",
      "  -8.84119578e+120 -8.84119578e+120]\n",
      " [-3.93259499e+121 -3.93259499e+121 -3.93259499e+121 ... -3.93259499e+121\n",
      "  -3.93259499e+121 -3.93259499e+121]\n",
      " [-2.74469657e+120 -2.74469657e+120 -2.74469657e+120 ... -2.74469657e+120\n",
      "  -2.74469657e+120 -2.74469657e+120]\n",
      " [-1.83760690e+123 -1.83760690e+123 -1.83760690e+123 ... -1.83760690e+123\n",
      "  -1.83760690e+123 -1.83760690e+123]]\n",
      "Epoch 40/100, Weights update: [[-4.11556847e+165 -4.11556847e+165 -4.11556847e+165 ... -4.11556847e+165\n",
      "  -4.11556847e+165 -4.11556847e+165]\n",
      " [-2.72504498e+162 -2.72504498e+162 -2.72504498e+162 ... -2.72504498e+162\n",
      "  -2.72504498e+162 -2.72504498e+162]\n",
      " [-1.21210960e+163 -1.21210960e+163 -1.21210960e+163 ... -1.21210960e+163\n",
      "  -1.21210960e+163 -1.21210960e+163]\n",
      " [-8.45973983e+161 -8.45973983e+161 -8.45973983e+161 ... -8.45973983e+161\n",
      "  -8.45973983e+161 -8.45973983e+161]\n",
      " [-5.66389613e+164 -5.66389613e+164 -5.66389613e+164 ... -5.66389613e+164\n",
      "  -5.66389613e+164 -5.66389613e+164]]\n",
      "Epoch 50/100, Weights update: [[-1.26850592e+207 -1.26850592e+207 -1.26850592e+207 ... -1.26850592e+207\n",
      "  -1.26850592e+207 -1.26850592e+207]\n",
      " [-8.39916945e+203 -8.39916945e+203 -8.39916945e+203 ... -8.39916945e+203\n",
      "  -8.39916945e+203 -8.39916945e+203]\n",
      " [-3.73598012e+204 -3.73598012e+204 -3.73598012e+204 ... -3.73598012e+204\n",
      "  -3.73598012e+204 -3.73598012e+204]\n",
      " [-2.60747213e+203 -2.60747213e+203 -2.60747213e+203 ... -2.60747213e+203\n",
      "  -2.60747213e+203 -2.60747213e+203]\n",
      " [-1.74573351e+206 -1.74573351e+206 -1.74573351e+206 ... -1.74573351e+206\n",
      "  -1.74573351e+206 -1.74573351e+206]]\n",
      "Epoch 60/100, Weights update: [[-3.90980562e+248 -3.90980562e+248 -3.90980562e+248 ... -3.90980562e+248\n",
      "  -3.90980562e+248 -3.90980562e+248]\n",
      " [-2.58880305e+245 -2.58880305e+245 -2.58880305e+245 ... -2.58880305e+245\n",
      "  -2.58880305e+245 -2.58880305e+245]\n",
      " [-1.15150870e+246 -1.15150870e+246 -1.15150870e+246 ... -1.15150870e+246\n",
      "  -1.15150870e+246 -1.15150870e+246]\n",
      " [-8.03678486e+244 -8.03678486e+244 -8.03678486e+244 ... -8.03678486e+244\n",
      "  -8.03678486e+244 -8.03678486e+244]\n",
      " [-5.38072276e+247 -5.38072276e+247 -5.38072276e+247 ... -5.38072276e+247\n",
      "  -5.38072276e+247 -5.38072276e+247]]\n",
      "Epoch 70/100, Weights update: [[-1.20508543e+290 -1.20508543e+290 -1.20508543e+290 ... -1.20508543e+290\n",
      "  -1.20508543e+290 -1.20508543e+290]\n",
      " [-7.97924277e+286 -7.97924277e+286 -7.97924277e+286 ... -7.97924277e+286\n",
      "  -7.97924277e+286 -7.97924277e+286]\n",
      " [-3.54919526e+287 -3.54919526e+287 -3.54919526e+287 ... -3.54919526e+287\n",
      "  -3.54919526e+287 -3.54919526e+287]\n",
      " [-2.47710839e+286 -2.47710839e+286 -2.47710839e+286 ... -2.47710839e+286\n",
      "  -2.47710839e+286 -2.47710839e+286]\n",
      " [-1.65845344e+289 -1.65845344e+289 -1.65845344e+289 ... -1.65845344e+289\n",
      "  -1.65845344e+289 -1.65845344e+289]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_23380\\3701760364.py:12: RuntimeWarning: overflow encountered in matmul\n",
      "  gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_23380\\3701760364.py:12: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_23380\\3701760364.py:38: RuntimeWarning: invalid value encountered in subtract\n",
      "  weights = weights - learning_rate * gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Weights update: [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Epoch 90/100, Weights update: [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "Epoch 100/100, Weights update: [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m parallel_predict(X_test, weights)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Threshold predictions to get binary classification results\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Calculate and print evaluation metrics\u001b[39;00m\n\u001b[0;32m     51\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_labels)\n",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m parallel_predict(X_test, weights)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Threshold predictions to get binary classification results\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Calculate and print evaluation metrics\u001b[39;00m\n\u001b[0;32m     51\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_labels)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Training loop with optimizations\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: calculate predictions\n",
    "    predictions = batch_predict(X_train, weights)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    gradients = compute_gradients(X_train, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
