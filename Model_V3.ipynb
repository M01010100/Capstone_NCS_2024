{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('payment_fraud.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['paymentMethod_encoded'] = label_encoder.fit_transform(df['paymentMethod'])\n",
    "\n",
    "features = ['accountAgeDays', 'numItems', 'localTime', 'paymentMethod_encoded', 'paymentMethodAgeDays']\n",
    "X = df[features].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
<<<<<<< HEAD
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data and transform it\n",
    "X_test = scaler.transform(X_test)  # Transform test data using the same scaler\n",
    "X_scaled = scaler.transform(X)  # Transform all data"
=======
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)  # Fit on training data and transform it\n",
    "#X_test = scaler.transform(X_test)  # Transform test data using the same scaler\n"
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encryption setup with TenSEAL\n",
<<<<<<< HEAD
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=16384, coeff_mod_bit_sizes=[60, 40, 40, 60, 60])\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[60, 40, 60])\n",
    "\n",
=======
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21,40])\n",
    "#context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=16384, coeff_mod_bit_sizes=[60, 40, 40, 60, 60])\n",
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
    "context.generate_galois_keys()\n",
    "context.global_scale = 2 ** 40\n",
    "\n",
    "# Encrypt training and testing data\n",
    "X_train_encrypted = [ts.ckks_vector(context, x) for x in X_train]\n",
    "X_test_encrypted = [ts.ckks_vector(context, x) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_tenseal_cpp.Ciphertext object at 0x000002105F182730>]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encrypted[0].ciphertext())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31376, 1)\n",
<<<<<<< HEAD
      "[[<tenseal.tensors.ckksvector.CKKSVector object at 0x000002105F1C6B90>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x000002105F1C6C80>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x00000210370F2560>]\n",
      " ...\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x00000216EDC3E4D0>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x00000216EDC3E530>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x00000216EDC3E590>]]\n"
=======
      "(31376, 1)\n",
      "[[<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC1716C0>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC173160>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BA9960A30>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BA98621A0>]\n",
      " [<tenseal.tensors.ckksvector.CKKSVector object at 0x0000025BEC1731C0>]]\n"
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
     ]
    }
   ],
   "source": [
    "#X_encrypted = [ts.ckks_vector(context, x) for x in X_scaled]\n",
    "X_train_encrypted_np = np.array( X_train_encrypted)\n",
    "#X_test_encrypted_np = np.array( X_test_encrypted)\n",
    "X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], -1)\n",
    "#X_train_encrypted_np = X_train_encrypted_np.reshape(X_train_encrypted_np.shape[0], -1)\n",
    "#X_test_encrypted_np = X_test_encrypted_np.reshape(X_test_encrypted_np.shape[0], X_test_encrypted_np.shape[1])\n",
    "print(X_train_encrypted_np.shape)\n",
    "#print(X_test_encrypted_np.shape)\n",
<<<<<<< HEAD
    "print(X_train_encrypted_np)"
=======
    "print(X_train_encrypted_np.shape)\n",
    "print(X_train_encrypted_np[:5])\n"
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encrypted_np_small = X_train_encrypted_np[:100]  # Use only the first 100 samples\n",
    "y_train_small = y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train_encrypted_np.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Profile the training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{epochs}\")\n",
    "    predictions = batch_predict(X_train_encrypted_np, weights)\n",
    "    gradients = compute_gradients(X_train_encrypted_np, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):\n",
    "        print(\"NaN or Inf detected in predictions\")\n",
    "        break\n",
    "    if np.any(np.isnan(gradients)) or np.any(np.isinf(gradients)):\n",
    "        print(\"NaN or Inf detected in gradients\")\n",
    "        break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Weights update: [[-1.01414828 -1.01414828 -1.01414828 ... -1.01414828 -1.01414828\n",
      "  -1.01414828]\n",
      " [ 0.79496189  0.79496189  0.79496189 ...  0.79496189  0.79496189\n",
      "   0.79496189]\n",
      " [ 1.28891067  1.28891067  1.28891067 ...  1.28891067  1.28891067\n",
      "   1.28891067]\n",
      " [ 0.18209134  0.18209134  0.18209134 ...  0.18209134  0.18209134\n",
      "   0.18209134]\n",
      " [ 0.65946543  0.65946543  0.65946543 ...  0.65946543  0.65946543\n",
      "   0.65946543]]\n",
      "Epoch 20/100, Weights update: [[-0.93344452 -0.93344452 -0.93344452 ... -0.93344452 -0.93344452\n",
      "  -0.93344452]\n",
      " [ 0.71819373  0.71819373  0.71819373 ...  0.71819373  0.71819373\n",
      "   0.71819373]\n",
      " [ 1.16935576  1.16935576  1.16935576 ...  1.16935576  1.16935576\n",
      "   1.16935576]\n",
      " [ 0.1645925   0.1645925   0.1645925  ...  0.1645925   0.1645925\n",
      "   0.1645925 ]\n",
      " [ 0.6286293   0.6286293   0.6286293  ...  0.6286293   0.6286293\n",
      "   0.6286293 ]]\n",
      "Epoch 30/100, Weights update: [[-0.8598852  -0.8598852  -0.8598852  ... -0.8598852  -0.8598852\n",
      "  -0.8598852 ]\n",
      " [ 0.64870342  0.64870342  0.64870342 ...  0.64870342  0.64870342\n",
      "   0.64870342]\n",
      " [ 1.06094642  1.06094642  1.06094642 ...  1.06094642  1.06094642\n",
      "   1.06094642]\n",
      " [ 0.14876731  0.14876731  0.14876731 ...  0.14876731  0.14876731\n",
      "   0.14876731]\n",
      " [ 0.5981804   0.5981804   0.5981804  ...  0.5981804   0.5981804\n",
      "   0.5981804 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m batch_predict(X_train, weights)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate gradients and update weights\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradients\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Print progress every 10 epochs\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(X, y, predictions)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_gradients\u001b[39m(X, y, predictions):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Compute the gradients using mean squared error as an example\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     errors \u001b[38;5;241m=\u001b[39m predictions \u001b[38;5;241m-\u001b[39m y\n\u001b[1;32m---> 12\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m errors \u001b[38;5;241m/\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Mean of the gradient\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gradients\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> cf8c8b963f5427d1ebc403c3dfabb77757e76630
   "source": [
    "\n",
    "# Define functions if not already available\n",
    "def batch_predict(X, weights):\n",
    "    # Simple linear model prediction (e.g., X @ weights for matrix multiplication)\n",
    "    return X @ weights\n",
    "\n",
    "def compute_gradients(X, y, predictions):\n",
    "    # Compute the gradients using mean squared error as an example\n",
    "    errors = predictions - y\n",
    "    gradients = X.T @ errors / len(y)  # Mean of the gradient\n",
    "    return gradients\n",
    "\n",
    "def parallel_predict(X, weights):\n",
    "    # Parallelized version, could be similar to batch_predict if parallelism is not needed\n",
    "    return batch_predict(X, weights)\n",
    "\n",
    "# Load data (example placeholders)\n",
    "# Ensure that X_train, X_test, y_train, and y_test are properly defined before running this code\n",
    "# For example: X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize weights for a simple linear model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "output_dim = 1  # Binary classification output\n",
    "\n",
    "weights = np.random.randn(input_dim, output_dim)\n",
    "learning_rate = 0.01  # Reduced learning rate\n",
    "epochs = 100  # Reduced epochs\n",
    "\n",
    "# Training loop with optimizations\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: calculate predictions\n",
    "    predictions = batch_predict(X_train, weights)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    gradients = compute_gradients(X_train, y_train, predictions)\n",
    "    weights = weights - learning_rate * gradients\n",
    "\n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Weights update: {weights}\")\n",
    "\n",
    "# Check predictions on test data\n",
    "y_pred = parallel_predict(X_test, weights)\n",
    "\n",
    "# Threshold predictions to get binary classification results\n",
    "y_pred_labels = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "precision = precision_score(y_test, y_pred_labels, zero_division=1)  # Handle zero precision cases\n",
    "recall = recall_score(y_test, y_pred_labels)\n",
    "f1 = f1_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
